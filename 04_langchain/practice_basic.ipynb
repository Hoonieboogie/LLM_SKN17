{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc5b6db",
   "metadata": {},
   "source": [
    "# Practice\n",
    "> Model I/O부터 Memory까지 연습하고 넘어가 봅시다🐿️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a85846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323bc81",
   "metadata": {},
   "source": [
    "### 1. Chain을 이용한 Simple LLM\n",
    "\n",
    "1. PromptTemplate - System message, User message\n",
    "2. LLM (model)\n",
    "3. OutputParser\n",
    "- Chain ~> 간단한 질의를 보내 응답 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6b7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain_openai langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58cbd0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PromptTemplate 생성\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "system_message = \"너는 위트있게 단답하는 챗봇이야. 이럴 때는 어떻게 해야할까?\\n{emotion}\"\n",
    "\n",
    "prompt_tpl = PromptTemplate(\n",
    "    template = system_message,\n",
    "    input_variables = ['emotion'],\n",
    ")\n",
    "\n",
    "user_message = '내 기분이 너무 안 좋아.'\n",
    "prompt = prompt_tpl.format(emotion=user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c478c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LLM 모델 요청을 위한 인스턴스 생성\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "endpoint = HuggingFaceEndpoint(\n",
    "    repo_id='MLP-KTLim/llama-3-Korean-Bllossom-8B', # conversational 태그가 있는 모델만 가능함\n",
    "    task='text-generation',\n",
    "    max_new_tokens=1024,\n",
    "    huggingfacehub_api_token=HF_TOKEN\n",
    ")\n",
    "\n",
    "hf_model = ChatHuggingFace(\n",
    "    llm=endpoint,\n",
    "    verbos=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac631b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 응답 문자열만 출력하기 위한 OutputParser 생성\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "string_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc9fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기분이 안좋으니까, 기분 좋은 음식을 추천해줄게. 하지만, 그것도 안되면, 기분이 좋아지는 음악을 틀어줄게!\n"
     ]
    }
   ],
   "source": [
    "# 4. Chain 생성 및 질의\n",
    "chain = prompt_tpl | hf_model | string_parser\n",
    "\n",
    "output = chain.invoke(input={'emotion':'나 기분이 안좋아.'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d81cb",
   "metadata": {},
   "source": [
    "### 2. 단계별 ChatBot\n",
    "> 내 이름을 알려주고, 내 이름이 뭐냐고 물어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e236d4",
   "metadata": {},
   "source": [
    "1. 그냥 Chat\n",
    "- ChatOpenAI, HumanMessage 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e5b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49d2076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='안녕 나는 훈이야', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "query = input()\n",
    "\n",
    "message = HumanMessage(content=query)\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b722973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕, 훈이! 만나서 반가워. 어떻게 지내?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 14, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bda4d3a2c', 'id': 'chatcmpl-CCLtSkhik0wN54yH8GNGZNNPuPbj8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c2ca71f6-799e-4585-a6e4-9d06a5c30908-0', usage_metadata={'input_tokens': 14, 'output_tokens': 17, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(message.content)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656d4420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕, 훈이! 만나서 반가워. 어떻게 지내?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c87d8",
   "metadata": {},
   "source": [
    "2. 직접 대화 맥락 유지\n",
    "- ChatOpenAI, HumanMessage, AIMessage만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec664852",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b30fbbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 이름은 훈이입니다! 맞나요? 더 이야기하고 싶은 것이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "human_message = HumanMessage(content=query)\n",
    "\n",
    "messages.append(human_message)\n",
    "#print(len(messages))\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "model_message = model.invoke(messages) # AIMessage\n",
    "messages.append(model_message)\n",
    "print(model_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9164ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나: 안녕 나는 훈이야\n",
      "봇: 안녕하세요, 훈이! 만나서 반가워요. 어떻게 도와드릴까요?\n",
      "나: 나랑 이야기 할래?\n",
      "봇: 물론이죠! 어떤 이야기를 나눌까요? 궁금한 것이나 하고 싶은 이야기가 있으면 편하게 말해 주세요.\n",
      "나: 근데 내 이름 뭐라고?\n",
      "봇: 당신의 이름은 훈이입니다! 맞나요? 더 이야기하고 싶은 것이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    if type(message) == HumanMessage:\n",
    "        print(\"나:\", message.content)\n",
    "    else:\n",
    "        print(\"봇:\", message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8bdffe",
   "metadata": {},
   "source": [
    "3. Memory로 대화 맥락 유지\n",
    "- 아래 내용을 사용\n",
    "    - langchain_openai의 ChatOpenAI\n",
    "    - langchain_core.messages의 클래스\n",
    "    - langchain_core.runnables의 클래스\n",
    "    - langchain_core.prompts의 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1065c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.messages = []\n",
    "    \n",
    "    def add_messages(self, messages):\n",
    "        self.messages.extend(messages)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.messages = []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'InMemoryHistory(messages={str(self.messages)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76302011",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee3e66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template('너는 {skill}을 잘하는 AI 어시스턴트야'),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    HumanMessagePromptTemplate.from_template('{query}')\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_by_session_id,\n",
    "    input_messages_key='query',\n",
    "    history_messages_key='history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51f3decf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['history', 'query', 'skill'], input_types={'history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000196F9DF7EC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['skill'], input_types={}, partial_variables={}, template='너는 {skill}을 잘하는 AI 어시스턴트야'), additional_kwargs={}), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c5989ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈이란 이름이시죠! 맞나요?\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "response = chain_with_history.invoke(\n",
    "    {'skill': '대화', 'query': query},\n",
    "    config={'configurable': {'session_id': '일상대화'}}\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "137e5399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'일상대화': InMemoryHistory(messages=[HumanMessage(content='내 이름이 뭐라고?', additional_kwargs={}, response_metadata={}), AIMessage(content='죄송하지만, 당신의 이름을 알지 못합니다. 이름을 알려주시면 기억하겠습니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 31, 'total_tokens': 53, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bda4d3a2c', 'id': 'chatcmpl-CCHbQkPU85olvCBc1pYTOFPwNpJ1u', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7990a087-7ae1-4ad8-b64d-b21157564100-0', usage_metadata={'input_tokens': 31, 'output_tokens': 22, 'total_tokens': 53, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='아 미안 내 이름은 훈이야', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, 훈이! 만나서 반가워요. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 71, 'total_tokens': 92, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bda4d3a2c', 'id': 'chatcmpl-CCHbtNHXEiUtLxyjzMrmIbvQK7cLP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--27386d50-291b-4d9c-928d-67b34f793ab0-0', usage_metadata={'input_tokens': 71, 'output_tokens': 21, 'total_tokens': 92, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내 이름이 뭐라고?', additional_kwargs={}, response_metadata={}), AIMessage(content='훈이란 이름이시죠! 맞나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 106, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bda4d3a2c', 'id': 'chatcmpl-CCHc6OpKPoydTSJ8Ab3kkR9ueX2ze', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5937d383-2631-4492-8ff8-7afa34749f01-0', usage_metadata={'input_tokens': 106, 'output_tokens': 11, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f288992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나: 내 이름이 뭐라고?\n",
      "봇: 죄송하지만, 당신의 이름을 알지 못합니다. 이름을 알려주시면 기억하겠습니다!\n",
      "나: 아 미안 내 이름은 훈이야\n",
      "봇: 안녕하세요, 훈이! 만나서 반가워요. 어떻게 도와드릴까요?\n",
      "나: 내 이름이 뭐라고?\n",
      "봇: 훈이란 이름이시죠! 맞나요?\n"
     ]
    }
   ],
   "source": [
    "for message in store['일상대화'].messages:\n",
    "    if type(message) == HumanMessage:\n",
    "        print(\"나:\", message.content)\n",
    "    else:\n",
    "        print(\"봇:\", message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
