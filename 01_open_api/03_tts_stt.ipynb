{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9e26b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc84b0f",
   "metadata": {},
   "source": [
    "# TTS (Text-To-Speech)\n",
    "\n",
    "- TTS 모델은 텍스트를 자연스러운 음성으로 변환하는 AI 모델이다.\n",
    "    - https://platform.openai.com/docs/models\n",
    "    - tts-1 : 실시간 텍스트-음성 변환에 최적화된 최신 모델로 속도에 중점. 텍스트를 음성으로 빠르게 변환하는 기능 제공\n",
    "    - tts-1-hd : 품질에 최적화된 최신 텍스트-음성 변환 모델로 높은 품질에 중점. 음성의 자연스러움과 선명도 강조\n",
    "\n",
    "- 음성 선택지\n",
    "    - https://platform.openai.com/docs/guides/text-to-speech#text-to-speech-models\n",
    "    - Alloy: 부드럽고 자연스러운 톤의 음성\n",
    "    - Echo: 명확하고 자신감 있는 음성\n",
    "    - Fable: 이야기 전달에 적합한 서정적인 음성\n",
    "    - Onyx: 전문적이고 신뢰감을 주는 음성\n",
    "    - Nova: 활기차고 에너지 넘치는 음성\n",
    "    - Shimmer: 부드럽고 진정시키는 음성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca41e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "text = \"한번만, 딱 한 번만 말할거니까 잘들어. 너 좋아해. 니가 남자건 외계인이건 이제 상관 안해. 정리하는 거 힘들어서 못해먹겠으니까. 가보자 갈때까지. 한 번 가보자.\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model='tts-1',\n",
    "    voice='coral',\n",
    "    input=text\n",
    ") as response:\n",
    "    response.stream_to_file('tts_output.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466cde35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e4d7d5",
   "metadata": {},
   "source": [
    "# STT (Speech-To-Text)\n",
    "\n",
    "\n",
    "\n",
    "- Whisper는 OpenAI에서 개발한 범용 음성 인식 모델로, 다양한 오디오 데이터셋을 학습하여 다국어 음성 인식, 음성 번역, 언어 식별 등의 작업을 수행할 수 있다.\n",
    "- Whisper v2-large 모델은 현재 API를 통해 'whisper-1'이라는 이름으로 제공되고 있다.\n",
    "    - https://platform.openai.com/docs/models/whisper-1\n",
    "- 오픈 소스 버전의 Whisper와 API를 통한 Whisper는 기능적으로 동일하지만, API를 통해 제공되는 버전은 최적화된 추론 과정을 거쳐 다른 방법에 비해 더 빠르게 동작한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533a10c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='한 번만 딱 한 번만 말할 거니까 잘 들어 너 좋아해 니가 남자건 외계인이건 이제 상관안해 정리하는거 힘들어서 못해먹겠으니까 가보자 갈 때까지 한번 가보자', logprobs=None, usage=UsageDuration(seconds=13.0, type='duration'))\n"
     ]
    }
   ],
   "source": [
    "with open(\"tts_output.mp3\", \"rb\") as f:\n",
    "    transcriptions = client.audio.transcriptions.create(\n",
    "        model='whisper-1',\n",
    "        file=f\n",
    "    )\n",
    "\n",
    "    print(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df172c9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd5229",
   "metadata": {},
   "source": [
    "# gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac540ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Using cached gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from gtts) (2.32.5)\n",
      "Collecting click<8.2,>=7.1 (from gtts)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2025.8.3)\n",
      "Using cached gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Installing collected packages: click, gtts\n",
      "\n",
      "   ---------------------------------------- 0/2 [click]\n",
      "   ---------------------------------------- 0/2 [click]\n",
      "   ---------------------------------------- 0/2 [click]\n",
      "   -------------------- ------------------- 1/2 [gtts]\n",
      "   -------------------- ------------------- 1/2 [gtts]\n",
      "   -------------------- ------------------- 1/2 [gtts]\n",
      "   -------------------- ------------------- 1/2 [gtts]\n",
      "   ---------------------------------------- 2/2 [gtts]\n",
      "\n",
      "Successfully installed click-8.1.8 gtts-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa2679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "google_tts = gTTS(\n",
    "    text=\"안녕하세요, 저는 다람쥐입니다. 여러분 행복하세요~!\",\n",
    "    lang=\"ko\"\n",
    ")\n",
    "\n",
    "google_tts.save('gtts_output.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c95707",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9cf6d3",
   "metadata": {},
   "source": [
    "# SpeechRecognition\n",
    "\n",
    "- ffmpeg 설치 필요! (mp3 > wav 파일 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6845e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Using cached speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from SpeechRecognition) (4.15.0)\n",
      "Using cached speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.14.3\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e009defa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pydub, pyaudio\n",
      "\n",
      "   ---------------------------------------- 0/2 [pydub]\n",
      "   -------------------- ------------------- 1/2 [pyaudio]\n",
      "   ---------------------------------------- 2/2 [pyaudio]\n",
      "\n",
      "Successfully installed pyaudio-0.2.14 pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    with sr.Microphone() as source:\n",
    "        print('말씀하세요.')\n",
    "        audio = recognizer.listen(source)\n",
    "        txt = recognizer.recognize_google(audio, language='ko-KR')\n",
    "        print(txt)\n",
    "\n",
    "        if txt == '종료':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 저는 다람쥐입니다 여러분 행복하세요 물결표\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "\n",
    "# mp3 -> wav 파일 변환\n",
    "audio = AudioSegment.from_mp3('gtts_output.mp3')\n",
    "audio.export('gtts_output_wav.wav', format='wav')\n",
    "\n",
    "# 오디오 파일 로드\n",
    "r = sr.Recognizer()\n",
    "input_audio = sr.AudioFile('gtts_output_wav.wav')\n",
    "\n",
    "# 오디오 데이터 객체 생성\n",
    "with input_audio as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "# 텍스트 변환\n",
    "result_txt = r.recognize_google(audio_data=audio, language='ko-KR')\n",
    "print(result_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
